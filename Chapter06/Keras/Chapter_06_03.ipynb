{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN on DLVM (GPU)\n",
    "In this notebook we will go through the steps of stacking layers together and seeing how it affects performance. In section we went through the steps of how the various types of layers and their properties affect the dimensions of the data passing through them. In this notebook we will look at the affect on performance so that we get an idea of stacking these layers can give us better performance. We will be basic this CNN on the VGG architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import pickle\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "EPOCHS = 30\n",
    "BATCHSIZE = 64\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "N_CLASSES = 10 # There are 10 classes in the CIFAR10 dataset\n",
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_cifar(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    # Scale pixel intensity\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "        \n",
    "    enc = OneHotEncoder(categorical_features='all')\n",
    "    fit = enc.fit(y_train)\n",
    "    y_train = fit.transform(y_train).toarray()\n",
    "    y_test = fit.transform(y_test).toarray()\n",
    "    \n",
    "    return (x_train.astype(np.float32), \n",
    "            y_train.astype(np.int32), \n",
    "            x_test.astype(np.float32), \n",
    "            y_test.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(m):\n",
    "    m.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = K.optimizers.SGD(LR, MOMENTUM),\n",
    "        metrics = ['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Data into format for library\n",
    "# x_train, y_train, x_test, y_test = prepare_cifar(*load_cifar(), channel_first=False)\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, y_train, x_test, y_test = prepare_cifar(x_train, y_train, x_test, y_test)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "Our first model will have 2 convolution layers and a max pooling layer. The classification layer will use softmax as we want it to only output a 1 for our specified class and 0 everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', name='fc1'))\n",
    "model.add(Dense(4096, activation='relu', name='fc2'))\n",
    "model.add(Dense(N_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = init_model(model) # Initialise model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=20,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_guess = model.predict(x_test, batch_size=BATCHSIZE)\n",
    "y_guess = np.argmax(y_guess, axis=-1)\n",
    "y_truth = np.argmax(y_test, axis=-1)\n",
    "print(\"Accuracy: \", sum(y_guess == y_truth)/len(y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model gets an accuracy of 72.8% on the test set after 20 epochs. We can also see that it achieves 100% on the training set a few epochs before we stop training. It would usually be prudent to stop the model earlier and there are usually callbacks that can be used in any of the frameworks to do this. We are simply not using these here to try and keep things simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 \n",
    "With the second model we will add a second convolution block. In keeping with the VGG architecture we will add two convolution layers each with 128 filters as well as a mac pooling layer. This time we will train it for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', name='fc1'))\n",
    "model.add(Dense(4096, activation='relu', name='fc2'))\n",
    "model.add(Dense(N_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = init_model(model) # Initialise model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_guess = model.predict(x_test, batch_size=BATCHSIZE)\n",
    "y_guess = np.argmax(y_guess, axis=-1)\n",
    "y_truth = np.argmax(y_test, axis=-1)\n",
    "print(\"Accuracy: \", sum(y_guess == y_truth)/len(y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does slightly better with an accuracy of 75.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 \n",
    "For our third model we will add a 3rd convolution block. This will be made up of 3 convolution layers each with 256 filters each. Again we will have a max pooling block at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', name='fc1'))\n",
    "model.add(Dense(4096, activation='relu', name='fc2'))\n",
    "model.add(Dense(N_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = init_model(model) # Initialise model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_guess = model.predict(x_test, batch_size=BATCHSIZE)\n",
    "y_guess = np.argmax(y_guess, axis=-1)\n",
    "y_truth = np.argmax(y_test, axis=-1)\n",
    "print(\"Accuracy: \", sum(y_guess == y_truth)/len(y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model reaches a accuracy of 76%. As you can see with each additional layer we get better results but the returns diminish with each succesive block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "Due to the large number of free parameters CNNs can benefit from regularisation. One way to refularise is to use a dropout layer which we talked about earlier. This layer will randomly during the forward pass zero a certain proportion of its outputs. This was also eployed by the authors of the VGG architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    " # Block 3\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu', name='fc2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(N_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = init_model(model) # Initialise model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_guess = model.predict(x_test, batch_size=BATCHSIZE)\n",
    "y_guess = np.argmax(y_guess, axis=-1)\n",
    "y_truth = np.argmax(y_test, axis=-1)\n",
    "print(\"Accuracy: \", sum(y_guess == y_truth)/len(y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our accuracy has increased further to 80%. The VGG architecture actually has even more layers than our final model but it was designed to tackle the ImageNet dataset which contains a lot more data than the CIFAR10 dataset. Adding further layers with the limited data available would quickly prove untenable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
